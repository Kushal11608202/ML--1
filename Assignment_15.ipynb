{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librarie's used are :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 1 (Importing the dataset from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "dig = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 2  {Splitting the dataset into training and testing sets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dig.data\n",
    "y = dig.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) For Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = SVC(kernel='linear')\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linPredict = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with linear kernel\n",
      "[[67  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 71  0  0  1  0  0  0  0  0]\n",
      " [ 0  0 66  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 69  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 78  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 81  0  1  0  1]\n",
      " [ 0  0  0  0  0  0 69  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 70  0  1]\n",
      " [ 0  3  0  0  0  1  0  0 61  0]\n",
      " [ 0  0  0  1  1  0  0  0  0 75]]\n"
     ]
    }
   ],
   "source": [
    "lin_CM = confusion_matrix(y_test, linPredict)\n",
    "print('Confusion Matrix with linear kernel')\n",
    "print(lin_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report taking linear kernel :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        67\n",
      "          1       0.96      0.99      0.97        72\n",
      "          2       1.00      1.00      1.00        66\n",
      "          3       0.99      0.97      0.98        71\n",
      "          4       0.97      1.00      0.99        78\n",
      "          5       0.98      0.98      0.98        83\n",
      "          6       1.00      1.00      1.00        69\n",
      "          7       0.99      0.99      0.99        71\n",
      "          8       0.98      0.94      0.96        65\n",
      "          9       0.97      0.97      0.97        77\n",
      "\n",
      "avg / total       0.98      0.98      0.98       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin_CR = classification_report(y_test, linPredict)\n",
    "print('Classification report taking linear kernel :')\n",
    "print(lin_CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) For Poly Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = SVC(kernel='poly')\n",
    "poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyPredict = poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with poly kernel :\n",
      "[[67  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 66  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 69  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 78  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 82  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 69  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 70  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 64  0]\n",
      " [ 0  0  0  1  0  0  0  1  0 75]]\n"
     ]
    }
   ],
   "source": [
    "poly_CM = confusion_matrix(y_test, polyPredict)\n",
    "print('Confusion Matrix with poly kernel :')\n",
    "print(poly_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report taking poly kernel :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        67\n",
      "          1       0.99      1.00      0.99        72\n",
      "          2       1.00      1.00      1.00        66\n",
      "          3       0.99      0.97      0.98        71\n",
      "          4       1.00      1.00      1.00        78\n",
      "          5       0.99      0.99      0.99        83\n",
      "          6       1.00      1.00      1.00        69\n",
      "          7       0.99      0.99      0.99        71\n",
      "          8       0.98      0.98      0.98        65\n",
      "          9       0.97      0.97      0.97        77\n",
      "\n",
      "avg / total       0.99      0.99      0.99       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poly_CR = classification_report(y_test, polyPredict)\n",
    "print('Classification report taking poly kernel :')\n",
    "print(poly_CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) For Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = SVC(kernel='sigmoid')\n",
    "sigmoid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigPredict = sigmoid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with Sigmoid kernel :\n",
      "[[ 0  0  0  1  0  0 66  0  0  0]\n",
      " [ 0  0  0  0  0  0 72  0  0  0]\n",
      " [ 0  0  0  0  0  0 66  0  0  0]\n",
      " [ 0  0  0  1  0  0 70  0  0  0]\n",
      " [ 0  0  0  0  0  0 78  0  0  0]\n",
      " [ 0  0  0  0  0  0 83  0  0  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  0]\n",
      " [ 0  0  0  2  0  0 69  0  0  0]\n",
      " [ 0  0  0  0  0  0 65  0  0  0]\n",
      " [ 0  0  0  0  0  0 77  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "sig_CM = confusion_matrix(y_test, sigPredict)\n",
    "print('Confusion Matrix with Sigmoid kernel :')\n",
    "print(sig_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report taking Sigmoid kernel :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        67\n",
      "          1       0.00      0.00      0.00        72\n",
      "          2       0.00      0.00      0.00        66\n",
      "          3       0.25      0.01      0.03        71\n",
      "          4       0.00      0.00      0.00        78\n",
      "          5       0.00      0.00      0.00        83\n",
      "          6       0.10      1.00      0.18        69\n",
      "          7       0.00      0.00      0.00        71\n",
      "          8       0.00      0.00      0.00        65\n",
      "          9       0.00      0.00      0.00        77\n",
      "\n",
      "avg / total       0.03      0.10      0.02       719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sig_CR = classification_report(y_test, sigPredict)\n",
    "print('Classification report taking Sigmoid kernel :')\n",
    "print(sig_CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) For Guassian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss = SVC(kernel='rbf')\n",
    "gauss.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gausPredict = gauss.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with gaussian kernel :\n",
      "[[32  0  0 35  0  0  0  0  0  0]\n",
      " [ 0 33  0 39  0  0  0  0  0  0]\n",
      " [ 0  0 44 22  0  0  0  0  0  0]\n",
      " [ 0  0  0 71  0  0  0  0  0  0]\n",
      " [ 0  0  0 58 20  0  0  0  0  0]\n",
      " [ 0  0  0 83  0  0  0  0  0  0]\n",
      " [ 0  0  0 16  0  0 53  0  0  0]\n",
      " [ 0  0  0 32  0  0  0 39  0  0]\n",
      " [ 0  0  0 35  0  0  0  0 30  0]\n",
      " [ 0  0  0 66  0  0  0  0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "gaus_CM = confusion_matrix(y_test, gausPredict)\n",
    "print('Confusion Matrix with gaussian kernel :')\n",
    "print(gaus_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report taking gaussian kernel :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.48      0.65        67\n",
      "          1       1.00      0.46      0.63        72\n",
      "          2       1.00      0.67      0.80        66\n",
      "          3       0.16      1.00      0.27        71\n",
      "          4       1.00      0.26      0.41        78\n",
      "          5       0.00      0.00      0.00        83\n",
      "          6       1.00      0.77      0.87        69\n",
      "          7       1.00      0.55      0.71        71\n",
      "          8       1.00      0.46      0.63        65\n",
      "          9       1.00      0.14      0.25        77\n",
      "\n",
      "avg / total       0.80      0.46      0.50       719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "gaus_CR = classification_report(y_test, gausPredict)\n",
    "print('Classification report taking gaussian kernel :')\n",
    "print(gaus_CR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

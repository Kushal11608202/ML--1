{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries used are given by :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 1 (Importing the dataset from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "dig = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 2 {Saving X(feature) and y(target) as dataframe's}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dig.data\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dig.target\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3 (Splitting the dataset to Training and Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 4 (Using Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = LogReg.predict(X_test)\n",
    "predict_prob = LogReg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9685185185185186"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Score is :')\n",
    "LogReg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9685185185185186"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy Score is : ')\n",
    "Accuracy_Score = met.accuracy_score(y_test, predict)\n",
    "Accuracy_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Logarithmic Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logarithmic Loss is : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16883201454067467"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_Loss = met.log_loss(y_test, predict_prob)\n",
    "print('Logarithmic Loss is : ')\n",
    "Log_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) R2 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9510678957408394"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_Score = met.r2_score(y_test, predict)\n",
    "print('R2 Score is :')\n",
    "R2_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Mean Absolution Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error is : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09444444444444444"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = met.mean_absolute_error(y_test, predict)\n",
    "print('Mean Absolute Error is : ')\n",
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error is : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39444444444444443"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = met.mean_squared_error(y_test, predict)\n",
    "print('Mean Squared Error is : ')\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 52,  0,  1,  0,  0,  1,  0,  1,  0],\n",
       "       [ 0,  0, 49,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 54,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  2,  0,  0, 59,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 57,  0,  1,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 45,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0,  0, 54,  0,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0,  0,  0, 55,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  2, 45]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con_Mat = met.confusion_matrix(y_test, predict)\n",
    "print('Confusion Matrix is :')\n",
    "Con_Mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report is :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        53\n",
      "          1       0.95      0.95      0.95        55\n",
      "          2       1.00      1.00      1.00        49\n",
      "          3       0.96      1.00      0.98        54\n",
      "          4       0.97      0.97      0.97        61\n",
      "          5       1.00      0.97      0.98        59\n",
      "          6       0.98      0.98      0.98        46\n",
      "          7       0.96      0.96      0.96        56\n",
      "          8       0.92      0.93      0.92        59\n",
      "          9       0.96      0.94      0.95        48\n",
      "\n",
      "avg / total       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Class_Rep = met.classification_report(y_test, predict)\n",
    "print('Classification Report is :')\n",
    "print(Class_Rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
